/usr/local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6
  return f(*args, **kwds)
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_1 (InputLayer)         (None, 72)                0
_________________________________________________________________
batch_normalization_1 (Batch (None, 72)                288
_________________________________________________________________
dense_1 (Dense)              (None, 12)                876
_________________________________________________________________
dropout_1 (Dropout)          (None, 12)                0
_________________________________________________________________
dense_2 (Dense)              (None, 1)                 13
=================================================================
Total params: 1,177
Trainable params: 1,033
Non-trainable params: 144
_________________________________________________________________
None
Train on 2547 samples, validate on 128 samples
Epoch 1/100
2018-07-16 09:15:57.056209: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2547/2547 [==============================] - 1s 267us/step - loss: 0.1801 - acc: 0.7381 - val_loss: 0.0868 - val_acc: 0.9375
Epoch 2/100
2547/2547 [==============================] - 0s 63us/step - loss: 0.1355 - acc: 0.8241 - val_loss: 0.0793 - val_acc: 0.9141
Epoch 3/100
2547/2547 [==============================] - 0s 62us/step - loss: 0.1173 - acc: 0.8575 - val_loss: 0.0747 - val_acc: 0.9219
Epoch 4/100
2547/2547 [==============================] - 0s 60us/step - loss: 0.1142 - acc: 0.8559 - val_loss: 0.0782 - val_acc: 0.9219
Epoch 5/100
2547/2547 [==============================] - 0s 61us/step - loss: 0.1112 - acc: 0.8649 - val_loss: 0.0773 - val_acc: 0.9219
Epoch 6/100
2547/2547 [==============================] - 0s 61us/step - loss: 0.1050 - acc: 0.8697 - val_loss: 0.0834 - val_acc: 0.8906
Epoch 7/100
2547/2547 [==============================] - 0s 59us/step - loss: 0.1058 - acc: 0.8689 - val_loss: 0.0767 - val_acc: 0.9219
Epoch 8/100
2547/2547 [==============================] - 0s 62us/step - loss: 0.1022 - acc: 0.8720 - val_loss: 0.0765 - val_acc: 0.9219
Epoch 9/100
2547/2547 [==============================] - 0s 78us/step - loss: 0.1057 - acc: 0.8669 - val_loss: 0.0699 - val_acc: 0.9219
Epoch 10/100
2547/2547 [==============================] - 0s 60us/step - loss: 0.0989 - acc: 0.8779 - val_loss: 0.0674 - val_acc: 0.9297
Epoch 11/100
2547/2547 [==============================] - 0s 65us/step - loss: 0.1012 - acc: 0.8779 - val_loss: 0.0678 - val_acc: 0.9297
Epoch 12/100
2547/2547 [==============================] - 0s 65us/step - loss: 0.0974 - acc: 0.8810 - val_loss: 0.0723 - val_acc: 0.9219
Epoch 13/100
2547/2547 [==============================] - 0s 61us/step - loss: 0.0971 - acc: 0.8803 - val_loss: 0.0685 - val_acc: 0.9297
Epoch 14/100
2547/2547 [==============================] - 0s 59us/step - loss: 0.0964 - acc: 0.8787 - val_loss: 0.0682 - val_acc: 0.9219
Epoch 15/100
2547/2547 [==============================] - 0s 73us/step - loss: 0.0982 - acc: 0.8799 - val_loss: 0.0707 - val_acc: 0.9219
Epoch 16/100
2547/2547 [==============================] - 0s 76us/step - loss: 0.0933 - acc: 0.8861 - val_loss: 0.0698 - val_acc: 0.9219
Epoch 17/100
2547/2547 [==============================] - 0s 76us/step - loss: 0.0964 - acc: 0.8799 - val_loss: 0.0670 - val_acc: 0.9219
Epoch 18/100
2547/2547 [==============================] - 0s 101us/step - loss: 0.0923 - acc: 0.8865 - val_loss: 0.0657 - val_acc: 0.9219
Epoch 19/100
2547/2547 [==============================] - 0s 63us/step - loss: 0.0976 - acc: 0.8759 - val_loss: 0.0698 - val_acc: 0.9219
Epoch 20/100
2547/2547 [==============================] - 0s 64us/step - loss: 0.0915 - acc: 0.8873 - val_loss: 0.0665 - val_acc: 0.9219
Epoch 21/100
2547/2547 [==============================] - 0s 64us/step - loss: 0.0969 - acc: 0.8767 - val_loss: 0.0674 - val_acc: 0.9219
Epoch 22/100
2547/2547 [==============================] - 0s 64us/step - loss: 0.0938 - acc: 0.8799 - val_loss: 0.0652 - val_acc: 0.9297
Epoch 23/100
2547/2547 [==============================] - 0s 64us/step - loss: 0.0928 - acc: 0.8806 - val_loss: 0.0694 - val_acc: 0.9219
Epoch 24/100
2547/2547 [==============================] - 0s 62us/step - loss: 0.0915 - acc: 0.8881 - val_loss: 0.0690 - val_acc: 0.9141
Epoch 25/100
2547/2547 [==============================] - 0s 62us/step - loss: 0.0915 - acc: 0.8865 - val_loss: 0.0671 - val_acc: 0.9219
Epoch 26/100
2547/2547 [==============================] - 0s 63us/step - loss: 0.0913 - acc: 0.8838 - val_loss: 0.0710 - val_acc: 0.9219
Epoch 27/100
2547/2547 [==============================] - 0s 63us/step - loss: 0.0909 - acc: 0.8838 - val_loss: 0.0681 - val_acc: 0.9297
Epoch 28/100
2547/2547 [==============================] - 0s 65us/step - loss: 0.0895 - acc: 0.8865 - val_loss: 0.0678 - val_acc: 0.9219
Epoch 29/100
2547/2547 [==============================] - 0s 65us/step - loss: 0.0905 - acc: 0.8850 - val_loss: 0.0668 - val_acc: 0.9297
Epoch 30/100
2547/2547 [==============================] - 0s 64us/step - loss: 0.0893 - acc: 0.8905 - val_loss: 0.0656 - val_acc: 0.9297
Epoch 31/100
2547/2547 [==============================] - 0s 63us/step - loss: 0.0954 - acc: 0.8814 - val_loss: 0.0670 - val_acc: 0.9297
Epoch 32/100
2547/2547 [==============================] - 0s 65us/step - loss: 0.0887 - acc: 0.8877 - val_loss: 0.0712 - val_acc: 0.9141
Epoch 33/100
2547/2547 [==============================] - 0s 63us/step - loss: 0.0918 - acc: 0.8826 - val_loss: 0.0659 - val_acc: 0.9219
Epoch 34/100
2547/2547 [==============================] - 0s 62us/step - loss: 0.0927 - acc: 0.8826 - val_loss: 0.0672 - val_acc: 0.9297
Epoch 35/100
2547/2547 [==============================] - 0s 62us/step - loss: 0.0914 - acc: 0.8838 - val_loss: 0.0682 - val_acc: 0.9141
Epoch 36/100
2547/2547 [==============================] - 0s 63us/step - loss: 0.0907 - acc: 0.8826 - val_loss: 0.0670 - val_acc: 0.9219
Epoch 37/100
2547/2547 [==============================] - 0s 61us/step - loss: 0.0871 - acc: 0.8893 - val_loss: 0.0666 - val_acc: 0.9219
Epoch 38/100
2547/2547 [==============================] - 0s 64us/step - loss: 0.0863 - acc: 0.8916 - val_loss: 0.0672 - val_acc: 0.9141
Epoch 39/100
2547/2547 [==============================] - 0s 65us/step - loss: 0.0856 - acc: 0.8885 - val_loss: 0.0702 - val_acc: 0.9141
Epoch 40/100
2547/2547 [==============================] - 0s 62us/step - loss: 0.0871 - acc: 0.8889 - val_loss: 0.0661 - val_acc: 0.9219
Epoch 41/100
2547/2547 [==============================] - 0s 64us/step - loss: 0.0911 - acc: 0.8814 - val_loss: 0.0699 - val_acc: 0.9141
Epoch 42/100
2547/2547 [==============================] - 0s 62us/step - loss: 0.0879 - acc: 0.8916 - val_loss: 0.0671 - val_acc: 0.9141
Epoch 43/100
2547/2547 [==============================] - 0s 62us/step - loss: 0.0889 - acc: 0.8893 - val_loss: 0.0671 - val_acc: 0.9219
Epoch 44/100
2547/2547 [==============================] - 0s 63us/step - loss: 0.0841 - acc: 0.8893 - val_loss: 0.0668 - val_acc: 0.9062
Epoch 45/100
2547/2547 [==============================] - 0s 64us/step - loss: 0.0874 - acc: 0.8850 - val_loss: 0.0670 - val_acc: 0.9219
Epoch 46/100
2547/2547 [==============================] - 0s 63us/step - loss: 0.0883 - acc: 0.8916 - val_loss: 0.0707 - val_acc: 0.9219
Epoch 47/100
2547/2547 [==============================] - 0s 63us/step - loss: 0.0856 - acc: 0.8963 - val_loss: 0.0640 - val_acc: 0.9141
Epoch 48/100
2547/2547 [==============================] - 0s 62us/step - loss: 0.0854 - acc: 0.8897 - val_loss: 0.0654 - val_acc: 0.9219
Epoch 49/100
2547/2547 [==============================] - 0s 63us/step - loss: 0.0916 - acc: 0.8787 - val_loss: 0.0646 - val_acc: 0.9219
Epoch 50/100
2547/2547 [==============================] - 0s 67us/step - loss: 0.0875 - acc: 0.8873 - val_loss: 0.0686 - val_acc: 0.9062
Epoch 51/100
2547/2547 [==============================] - 0s 63us/step - loss: 0.0839 - acc: 0.8936 - val_loss: 0.0650 - val_acc: 0.9219
Epoch 52/100
2547/2547 [==============================] - 0s 63us/step - loss: 0.0882 - acc: 0.8916 - val_loss: 0.0652 - val_acc: 0.9219
Epoch 53/100
2547/2547 [==============================] - 0s 63us/step - loss: 0.0877 - acc: 0.8861 - val_loss: 0.0651 - val_acc: 0.9141
Epoch 54/100
2547/2547 [==============================] - 0s 61us/step - loss: 0.0889 - acc: 0.8861 - val_loss: 0.0659 - val_acc: 0.9297
Epoch 55/100
2547/2547 [==============================] - 0s 63us/step - loss: 0.0870 - acc: 0.8893 - val_loss: 0.0656 - val_acc: 0.9062
Epoch 56/100
2547/2547 [==============================] - 0s 62us/step - loss: 0.0852 - acc: 0.8909 - val_loss: 0.0614 - val_acc: 0.9297
Epoch 57/100
2547/2547 [==============================] - 0s 62us/step - loss: 0.0848 - acc: 0.8905 - val_loss: 0.0638 - val_acc: 0.9219
Epoch 58/100
2547/2547 [==============================] - 0s 62us/step - loss: 0.0851 - acc: 0.8897 - val_loss: 0.0659 - val_acc: 0.9141
Epoch 59/100
2547/2547 [==============================] - 0s 62us/step - loss: 0.0871 - acc: 0.8869 - val_loss: 0.0714 - val_acc: 0.9062
Epoch 60/100
2547/2547 [==============================] - 0s 64us/step - loss: 0.0836 - acc: 0.8936 - val_loss: 0.0647 - val_acc: 0.9219
Epoch 61/100
2547/2547 [==============================] - 0s 63us/step - loss: 0.0872 - acc: 0.8909 - val_loss: 0.0670 - val_acc: 0.9062
Epoch 62/100
2547/2547 [==============================] - 0s 63us/step - loss: 0.0841 - acc: 0.8916 - val_loss: 0.0674 - val_acc: 0.9062
Epoch 63/100
2547/2547 [==============================] - 0s 61us/step - loss: 0.0842 - acc: 0.8932 - val_loss: 0.0675 - val_acc: 0.9141
Epoch 64/100
2547/2547 [==============================] - 0s 63us/step - loss: 0.0855 - acc: 0.8897 - val_loss: 0.0676 - val_acc: 0.9062
Epoch 65/100
2547/2547 [==============================] - 0s 61us/step - loss: 0.0853 - acc: 0.8905 - val_loss: 0.0648 - val_acc: 0.9219
Epoch 66/100
2547/2547 [==============================] - 0s 62us/step - loss: 0.0868 - acc: 0.8924 - val_loss: 0.0651 - val_acc: 0.9219
Epoch 67/100
2547/2547 [==============================] - 0s 62us/step - loss: 0.0871 - acc: 0.8928 - val_loss: 0.0657 - val_acc: 0.9219
Epoch 68/100
2547/2547 [==============================] - 0s 62us/step - loss: 0.0872 - acc: 0.8916 - val_loss: 0.0685 - val_acc: 0.9141
Epoch 69/100
2547/2547 [==============================] - 0s 62us/step - loss: 0.0828 - acc: 0.8963 - val_loss: 0.0663 - val_acc: 0.9141
Epoch 70/100
2547/2547 [==============================] - 0s 61us/step - loss: 0.0883 - acc: 0.8865 - val_loss: 0.0643 - val_acc: 0.9297
Epoch 71/100
2547/2547 [==============================] - 0s 63us/step - loss: 0.0866 - acc: 0.8920 - val_loss: 0.0652 - val_acc: 0.9141
Epoch 72/100
2547/2547 [==============================] - 0s 63us/step - loss: 0.0877 - acc: 0.8912 - val_loss: 0.0641 - val_acc: 0.9297
Epoch 73/100
2547/2547 [==============================] - 0s 63us/step - loss: 0.0842 - acc: 0.8924 - val_loss: 0.0639 - val_acc: 0.9219
Epoch 74/100
2547/2547 [==============================] - 0s 64us/step - loss: 0.0823 - acc: 0.8952 - val_loss: 0.0687 - val_acc: 0.9062
Epoch 75/100
2547/2547 [==============================] - 0s 62us/step - loss: 0.0867 - acc: 0.8928 - val_loss: 0.0674 - val_acc: 0.9062
Epoch 76/100
2547/2547 [==============================] - 0s 62us/step - loss: 0.0852 - acc: 0.8932 - val_loss: 0.0730 - val_acc: 0.9219
Epoch 77/100
2547/2547 [==============================] - 0s 63us/step - loss: 0.0807 - acc: 0.8956 - val_loss: 0.0672 - val_acc: 0.9141
Epoch 78/100
2547/2547 [==============================] - 0s 63us/step - loss: 0.0841 - acc: 0.8924 - val_loss: 0.0665 - val_acc: 0.9062
Epoch 79/100
2547/2547 [==============================] - 0s 62us/step - loss: 0.0862 - acc: 0.8916 - val_loss: 0.0663 - val_acc: 0.9141
Epoch 80/100
2547/2547 [==============================] - 0s 63us/step - loss: 0.0882 - acc: 0.8893 - val_loss: 0.0667 - val_acc: 0.9297
Epoch 81/100
2547/2547 [==============================] - 0s 63us/step - loss: 0.0828 - acc: 0.8960 - val_loss: 0.0652 - val_acc: 0.9141
Epoch 82/100
2547/2547 [==============================] - 0s 67us/step - loss: 0.0803 - acc: 0.8975 - val_loss: 0.0670 - val_acc: 0.9141
Epoch 83/100
2547/2547 [==============================] - 0s 64us/step - loss: 0.0841 - acc: 0.8928 - val_loss: 0.0664 - val_acc: 0.9141
Epoch 84/100
2547/2547 [==============================] - 0s 62us/step - loss: 0.0853 - acc: 0.8912 - val_loss: 0.0657 - val_acc: 0.9141
Epoch 85/100
2547/2547 [==============================] - 0s 61us/step - loss: 0.0849 - acc: 0.8944 - val_loss: 0.0646 - val_acc: 0.9062
Epoch 86/100
2547/2547 [==============================] - 0s 62us/step - loss: 0.0834 - acc: 0.8940 - val_loss: 0.0632 - val_acc: 0.9219
Epoch 87/100
2547/2547 [==============================] - 0s 63us/step - loss: 0.0845 - acc: 0.8905 - val_loss: 0.0644 - val_acc: 0.9297
Epoch 88/100
2547/2547 [==============================] - 0s 65us/step - loss: 0.0820 - acc: 0.8952 - val_loss: 0.0644 - val_acc: 0.9062
Epoch 89/100
2547/2547 [==============================] - 0s 64us/step - loss: 0.0858 - acc: 0.8889 - val_loss: 0.0659 - val_acc: 0.9141
Epoch 90/100
2547/2547 [==============================] - 0s 64us/step - loss: 0.0832 - acc: 0.8901 - val_loss: 0.0634 - val_acc: 0.9141
Epoch 91/100
2547/2547 [==============================] - 0s 62us/step - loss: 0.0817 - acc: 0.8948 - val_loss: 0.0622 - val_acc: 0.9297
Epoch 92/100
2547/2547 [==============================] - 0s 63us/step - loss: 0.0837 - acc: 0.8932 - val_loss: 0.0651 - val_acc: 0.9219
Epoch 93/100
2547/2547 [==============================] - 0s 61us/step - loss: 0.0806 - acc: 0.8983 - val_loss: 0.0653 - val_acc: 0.9141
Epoch 94/100
2547/2547 [==============================] - 0s 62us/step - loss: 0.0825 - acc: 0.8979 - val_loss: 0.0691 - val_acc: 0.9062
Epoch 95/100
2547/2547 [==============================] - 0s 62us/step - loss: 0.0846 - acc: 0.8960 - val_loss: 0.0631 - val_acc: 0.9297
Epoch 96/100
2547/2547 [==============================] - 0s 65us/step - loss: 0.0830 - acc: 0.8956 - val_loss: 0.0640 - val_acc: 0.9297
Epoch 97/100
2547/2547 [==============================] - 0s 64us/step - loss: 0.0803 - acc: 0.8956 - val_loss: 0.0652 - val_acc: 0.9141
Epoch 98/100
2547/2547 [==============================] - 0s 63us/step - loss: 0.0863 - acc: 0.8924 - val_loss: 0.0639 - val_acc: 0.9297
Epoch 99/100
2547/2547 [==============================] - 0s 62us/step - loss: 0.0772 - acc: 0.9026 - val_loss: 0.0630 - val_acc: 0.9297
Epoch 100/100
2547/2547 [==============================] - 0s 63us/step - loss: 0.0841 - acc: 0.8897 - val_loss: 0.0682 - val_acc: 0.9141
Data saved at /Users/brendonm/banded_low_resolution_time1531746973_epoch99.json
