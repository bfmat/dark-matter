/usr/local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6
  return f(*args, **kwds)
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_1 (InputLayer)         (None, 72)                0
_________________________________________________________________
batch_normalization_1 (Batch (None, 72)                288
_________________________________________________________________
dense_1 (Dense)              (None, 12)                876
_________________________________________________________________
dropout_1 (Dropout)          (None, 12)                0
_________________________________________________________________
dense_2 (Dense)              (None, 1)                 13
=================================================================
Total params: 1,177
Trainable params: 1,033
Non-trainable params: 144
_________________________________________________________________
None
Train on 3043 samples, validate on 128 samples
Epoch 1/100
2018-07-16 08:49:03.359397: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
3043/3043 [==============================] - 1s 223us/step - loss: 0.1875 - acc: 0.7213 - val_loss: 0.0814 - val_acc: 0.9375
Epoch 2/100
3043/3043 [==============================] - 0s 64us/step - loss: 0.1258 - acc: 0.8406 - val_loss: 0.0587 - val_acc: 0.9375
Epoch 3/100
3043/3043 [==============================] - 0s 64us/step - loss: 0.1150 - acc: 0.8593 - val_loss: 0.0542 - val_acc: 0.9297
Epoch 4/100
3043/3043 [==============================] - 0s 62us/step - loss: 0.1107 - acc: 0.8646 - val_loss: 0.0488 - val_acc: 0.9375
Epoch 5/100
3043/3043 [==============================] - 0s 63us/step - loss: 0.1073 - acc: 0.8715 - val_loss: 0.0463 - val_acc: 0.9453
Epoch 6/100
3043/3043 [==============================] - 0s 66us/step - loss: 0.1007 - acc: 0.8833 - val_loss: 0.0434 - val_acc: 0.9453
Epoch 7/100
3043/3043 [==============================] - 0s 61us/step - loss: 0.1027 - acc: 0.8715 - val_loss: 0.0422 - val_acc: 0.9453
Epoch 8/100
3043/3043 [==============================] - 0s 64us/step - loss: 0.1007 - acc: 0.8778 - val_loss: 0.0417 - val_acc: 0.9453
Epoch 9/100
3043/3043 [==============================] - 0s 64us/step - loss: 0.0987 - acc: 0.8837 - val_loss: 0.0433 - val_acc: 0.9453
Epoch 10/100
3043/3043 [==============================] - 0s 63us/step - loss: 0.1002 - acc: 0.8807 - val_loss: 0.0421 - val_acc: 0.9453
Epoch 11/100
3043/3043 [==============================] - 0s 64us/step - loss: 0.0972 - acc: 0.8814 - val_loss: 0.0410 - val_acc: 0.9453
Epoch 12/100
3043/3043 [==============================] - 0s 62us/step - loss: 0.0973 - acc: 0.8820 - val_loss: 0.0402 - val_acc: 0.9531
Epoch 13/100
3043/3043 [==============================] - 0s 60us/step - loss: 0.0947 - acc: 0.8870 - val_loss: 0.0388 - val_acc: 0.9609
Epoch 14/100
3043/3043 [==============================] - 0s 64us/step - loss: 0.0960 - acc: 0.8804 - val_loss: 0.0372 - val_acc: 0.9531
Epoch 15/100
3043/3043 [==============================] - 0s 63us/step - loss: 0.0960 - acc: 0.8837 - val_loss: 0.0408 - val_acc: 0.9531
Epoch 16/100
3043/3043 [==============================] - 0s 62us/step - loss: 0.0957 - acc: 0.8837 - val_loss: 0.0380 - val_acc: 0.9609
Epoch 17/100
3043/3043 [==============================] - 0s 65us/step - loss: 0.0931 - acc: 0.8876 - val_loss: 0.0371 - val_acc: 0.9609
Epoch 18/100
3043/3043 [==============================] - 0s 62us/step - loss: 0.0935 - acc: 0.8853 - val_loss: 0.0374 - val_acc: 0.9609
Epoch 19/100
3043/3043 [==============================] - 0s 64us/step - loss: 0.0923 - acc: 0.8879 - val_loss: 0.0370 - val_acc: 0.9609
Epoch 20/100
3043/3043 [==============================] - 0s 62us/step - loss: 0.0943 - acc: 0.8856 - val_loss: 0.0383 - val_acc: 0.9609
Epoch 21/100
3043/3043 [==============================] - 0s 64us/step - loss: 0.0922 - acc: 0.8860 - val_loss: 0.0369 - val_acc: 0.9609
Epoch 22/100
3043/3043 [==============================] - 0s 63us/step - loss: 0.0924 - acc: 0.8902 - val_loss: 0.0395 - val_acc: 0.9609
Epoch 23/100
3043/3043 [==============================] - 0s 63us/step - loss: 0.0877 - acc: 0.8968 - val_loss: 0.0386 - val_acc: 0.9609
Epoch 24/100
3043/3043 [==============================] - 0s 64us/step - loss: 0.0915 - acc: 0.8863 - val_loss: 0.0372 - val_acc: 0.9688
Epoch 25/100
3043/3043 [==============================] - 0s 62us/step - loss: 0.0871 - acc: 0.8925 - val_loss: 0.0383 - val_acc: 0.9609
Epoch 26/100
3043/3043 [==============================] - 0s 63us/step - loss: 0.0880 - acc: 0.8942 - val_loss: 0.0381 - val_acc: 0.9531
Epoch 27/100
3043/3043 [==============================] - 0s 65us/step - loss: 0.0879 - acc: 0.8866 - val_loss: 0.0384 - val_acc: 0.9531
Epoch 28/100
3043/3043 [==============================] - 0s 63us/step - loss: 0.0880 - acc: 0.8899 - val_loss: 0.0378 - val_acc: 0.9531
Epoch 29/100
3043/3043 [==============================] - 0s 63us/step - loss: 0.0891 - acc: 0.8879 - val_loss: 0.0393 - val_acc: 0.9609
Epoch 30/100
3043/3043 [==============================] - 0s 63us/step - loss: 0.0895 - acc: 0.8856 - val_loss: 0.0364 - val_acc: 0.9609
Epoch 31/100
3043/3043 [==============================] - 0s 62us/step - loss: 0.0860 - acc: 0.8932 - val_loss: 0.0386 - val_acc: 0.9531
Epoch 32/100
3043/3043 [==============================] - 0s 58us/step - loss: 0.0857 - acc: 0.8945 - val_loss: 0.0378 - val_acc: 0.9609
Epoch 33/100
3043/3043 [==============================] - 0s 62us/step - loss: 0.0868 - acc: 0.8893 - val_loss: 0.0357 - val_acc: 0.9609
Epoch 34/100
3043/3043 [==============================] - 0s 65us/step - loss: 0.0876 - acc: 0.8886 - val_loss: 0.0368 - val_acc: 0.9609
Epoch 35/100
3043/3043 [==============================] - 0s 63us/step - loss: 0.0837 - acc: 0.8952 - val_loss: 0.0366 - val_acc: 0.9688
Epoch 36/100
3043/3043 [==============================] - 0s 64us/step - loss: 0.0862 - acc: 0.8962 - val_loss: 0.0366 - val_acc: 0.9688
Epoch 37/100
3043/3043 [==============================] - 0s 64us/step - loss: 0.0850 - acc: 0.8906 - val_loss: 0.0377 - val_acc: 0.9531
Epoch 38/100
3043/3043 [==============================] - 0s 64us/step - loss: 0.0854 - acc: 0.8902 - val_loss: 0.0367 - val_acc: 0.9531
Epoch 39/100
3043/3043 [==============================] - 0s 62us/step - loss: 0.0834 - acc: 0.8922 - val_loss: 0.0366 - val_acc: 0.9609
Epoch 40/100
3043/3043 [==============================] - 0s 66us/step - loss: 0.0826 - acc: 0.8968 - val_loss: 0.0360 - val_acc: 0.9609
Epoch 41/100
3043/3043 [==============================] - 0s 63us/step - loss: 0.0854 - acc: 0.8889 - val_loss: 0.0383 - val_acc: 0.9531
Epoch 42/100
3043/3043 [==============================] - 0s 63us/step - loss: 0.0840 - acc: 0.8935 - val_loss: 0.0383 - val_acc: 0.9609
Epoch 43/100
3043/3043 [==============================] - 0s 66us/step - loss: 0.0812 - acc: 0.9014 - val_loss: 0.0368 - val_acc: 0.9609
Epoch 44/100
3043/3043 [==============================] - 0s 63us/step - loss: 0.0867 - acc: 0.8899 - val_loss: 0.0354 - val_acc: 0.9609
Epoch 45/100
3043/3043 [==============================] - 0s 62us/step - loss: 0.0892 - acc: 0.8810 - val_loss: 0.0352 - val_acc: 0.9609
Epoch 46/100
3043/3043 [==============================] - 0s 65us/step - loss: 0.0860 - acc: 0.8902 - val_loss: 0.0355 - val_acc: 0.9609
Epoch 47/100
3043/3043 [==============================] - 0s 63us/step - loss: 0.0832 - acc: 0.8922 - val_loss: 0.0361 - val_acc: 0.9609
Epoch 48/100
3043/3043 [==============================] - 0s 66us/step - loss: 0.0852 - acc: 0.8902 - val_loss: 0.0358 - val_acc: 0.9609
Epoch 49/100
3043/3043 [==============================] - 0s 62us/step - loss: 0.0849 - acc: 0.8916 - val_loss: 0.0356 - val_acc: 0.9531
Epoch 50/100
3043/3043 [==============================] - 0s 63us/step - loss: 0.0889 - acc: 0.8853 - val_loss: 0.0368 - val_acc: 0.9609
Epoch 51/100
3043/3043 [==============================] - 0s 63us/step - loss: 0.0821 - acc: 0.8916 - val_loss: 0.0378 - val_acc: 0.9453
Epoch 52/100
3043/3043 [==============================] - 0s 64us/step - loss: 0.0852 - acc: 0.8899 - val_loss: 0.0376 - val_acc: 0.9531
Epoch 53/100
3043/3043 [==============================] - 0s 64us/step - loss: 0.0808 - acc: 0.8985 - val_loss: 0.0352 - val_acc: 0.9609
Epoch 54/100
3043/3043 [==============================] - 0s 64us/step - loss: 0.0859 - acc: 0.8916 - val_loss: 0.0344 - val_acc: 0.9688
Epoch 55/100
3043/3043 [==============================] - 0s 66us/step - loss: 0.0819 - acc: 0.8965 - val_loss: 0.0366 - val_acc: 0.9531
Epoch 56/100
3043/3043 [==============================] - 0s 67us/step - loss: 0.0841 - acc: 0.8952 - val_loss: 0.0375 - val_acc: 0.9609
Epoch 57/100
3043/3043 [==============================] - 0s 65us/step - loss: 0.0814 - acc: 0.8965 - val_loss: 0.0382 - val_acc: 0.9453
Epoch 58/100
3043/3043 [==============================] - 0s 67us/step - loss: 0.0835 - acc: 0.8942 - val_loss: 0.0368 - val_acc: 0.9453
Epoch 59/100
3043/3043 [==============================] - 0s 65us/step - loss: 0.0870 - acc: 0.8896 - val_loss: 0.0367 - val_acc: 0.9453
Epoch 60/100
3043/3043 [==============================] - 0s 65us/step - loss: 0.0832 - acc: 0.8935 - val_loss: 0.0358 - val_acc: 0.9609
Epoch 61/100
3043/3043 [==============================] - 0s 65us/step - loss: 0.0788 - acc: 0.8994 - val_loss: 0.0370 - val_acc: 0.9609
Epoch 62/100
3043/3043 [==============================] - 0s 64us/step - loss: 0.0840 - acc: 0.8958 - val_loss: 0.0358 - val_acc: 0.9609
Epoch 63/100
3043/3043 [==============================] - 0s 63us/step - loss: 0.0814 - acc: 0.8994 - val_loss: 0.0350 - val_acc: 0.9609
Epoch 64/100
3043/3043 [==============================] - 0s 63us/step - loss: 0.0824 - acc: 0.8909 - val_loss: 0.0349 - val_acc: 0.9609
Epoch 65/100
3043/3043 [==============================] - 0s 63us/step - loss: 0.0803 - acc: 0.8981 - val_loss: 0.0348 - val_acc: 0.9531
Epoch 66/100
3043/3043 [==============================] - 0s 67us/step - loss: 0.0795 - acc: 0.9017 - val_loss: 0.0383 - val_acc: 0.9531
Epoch 67/100
3043/3043 [==============================] - 0s 63us/step - loss: 0.0799 - acc: 0.8929 - val_loss: 0.0377 - val_acc: 0.9453
Epoch 68/100
3043/3043 [==============================] - 0s 64us/step - loss: 0.0853 - acc: 0.8870 - val_loss: 0.0364 - val_acc: 0.9531
Epoch 69/100
3043/3043 [==============================] - 0s 63us/step - loss: 0.0808 - acc: 0.8952 - val_loss: 0.0361 - val_acc: 0.9531
Epoch 70/100
3043/3043 [==============================] - 0s 63us/step - loss: 0.0796 - acc: 0.9008 - val_loss: 0.0379 - val_acc: 0.9531
Epoch 71/100
3043/3043 [==============================] - 0s 64us/step - loss: 0.0798 - acc: 0.8945 - val_loss: 0.0360 - val_acc: 0.9453
Epoch 72/100
3043/3043 [==============================] - 0s 63us/step - loss: 0.0800 - acc: 0.8955 - val_loss: 0.0376 - val_acc: 0.9453
Epoch 73/100
3043/3043 [==============================] - 0s 63us/step - loss: 0.0806 - acc: 0.8935 - val_loss: 0.0380 - val_acc: 0.9453
Epoch 74/100
3043/3043 [==============================] - 0s 64us/step - loss: 0.0806 - acc: 0.8971 - val_loss: 0.0372 - val_acc: 0.9453
Epoch 75/100
3043/3043 [==============================] - 0s 65us/step - loss: 0.0754 - acc: 0.9054 - val_loss: 0.0364 - val_acc: 0.9531
Epoch 76/100
3043/3043 [==============================] - 0s 62us/step - loss: 0.0793 - acc: 0.8955 - val_loss: 0.0363 - val_acc: 0.9531
Epoch 77/100
3043/3043 [==============================] - 0s 64us/step - loss: 0.0819 - acc: 0.8948 - val_loss: 0.0352 - val_acc: 0.9531
Epoch 78/100
3043/3043 [==============================] - 0s 63us/step - loss: 0.0796 - acc: 0.8945 - val_loss: 0.0381 - val_acc: 0.9453
Epoch 79/100
3043/3043 [==============================] - 0s 63us/step - loss: 0.0807 - acc: 0.8975 - val_loss: 0.0359 - val_acc: 0.9531
Epoch 80/100
3043/3043 [==============================] - 0s 64us/step - loss: 0.0780 - acc: 0.9011 - val_loss: 0.0376 - val_acc: 0.9453
Epoch 81/100
3043/3043 [==============================] - 0s 64us/step - loss: 0.0815 - acc: 0.8935 - val_loss: 0.0381 - val_acc: 0.9531
Epoch 82/100
3043/3043 [==============================] - 0s 63us/step - loss: 0.0799 - acc: 0.8975 - val_loss: 0.0369 - val_acc: 0.9453
Epoch 83/100
3043/3043 [==============================] - 0s 63us/step - loss: 0.0799 - acc: 0.8935 - val_loss: 0.0363 - val_acc: 0.9453
Epoch 84/100
3043/3043 [==============================] - 0s 64us/step - loss: 0.0821 - acc: 0.8952 - val_loss: 0.0354 - val_acc: 0.9531
Epoch 85/100
3043/3043 [==============================] - 0s 63us/step - loss: 0.0772 - acc: 0.9034 - val_loss: 0.0372 - val_acc: 0.9453
Epoch 86/100
3043/3043 [==============================] - 0s 65us/step - loss: 0.0822 - acc: 0.8968 - val_loss: 0.0379 - val_acc: 0.9531
Epoch 87/100
3043/3043 [==============================] - 0s 64us/step - loss: 0.0783 - acc: 0.9027 - val_loss: 0.0371 - val_acc: 0.9453
Epoch 88/100
3043/3043 [==============================] - 0s 63us/step - loss: 0.0783 - acc: 0.8962 - val_loss: 0.0357 - val_acc: 0.9531
Epoch 89/100
3043/3043 [==============================] - 0s 63us/step - loss: 0.0789 - acc: 0.9004 - val_loss: 0.0359 - val_acc: 0.9531
Epoch 90/100
3043/3043 [==============================] - 0s 63us/step - loss: 0.0801 - acc: 0.8971 - val_loss: 0.0374 - val_acc: 0.9453
Epoch 91/100
3043/3043 [==============================] - 0s 64us/step - loss: 0.0808 - acc: 0.8948 - val_loss: 0.0363 - val_acc: 0.9453
Epoch 92/100
3043/3043 [==============================] - 0s 63us/step - loss: 0.0777 - acc: 0.9021 - val_loss: 0.0359 - val_acc: 0.9453
Epoch 93/100
3043/3043 [==============================] - 0s 64us/step - loss: 0.0776 - acc: 0.9037 - val_loss: 0.0363 - val_acc: 0.9531
Epoch 94/100
3043/3043 [==============================] - 0s 64us/step - loss: 0.0812 - acc: 0.8922 - val_loss: 0.0366 - val_acc: 0.9453
Epoch 95/100
3043/3043 [==============================] - 0s 63us/step - loss: 0.0806 - acc: 0.8955 - val_loss: 0.0356 - val_acc: 0.9609
Epoch 96/100
3043/3043 [==============================] - 0s 63us/step - loss: 0.0771 - acc: 0.9021 - val_loss: 0.0371 - val_acc: 0.9531
Epoch 97/100
3043/3043 [==============================] - 0s 63us/step - loss: 0.0806 - acc: 0.8932 - val_loss: 0.0367 - val_acc: 0.9531
Epoch 98/100
3043/3043 [==============================] - 0s 65us/step - loss: 0.0792 - acc: 0.8948 - val_loss: 0.0376 - val_acc: 0.9453
Epoch 99/100
3043/3043 [==============================] - 0s 63us/step - loss: 0.0788 - acc: 0.8991 - val_loss: 0.0347 - val_acc: 0.9609
Epoch 100/100
3043/3043 [==============================] - 0s 64us/step - loss: 0.0791 - acc: 0.8988 - val_loss: 0.0359 - val_acc: 0.9609
Data saved at /Users/brendonm/banded_low_resolution_time1531745363_epoch99.json
