/usr/local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
Using TensorFlow backend.
/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6
  return f(*args, **kwds)
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_1 (InputLayer)         (None, 72)                0
_________________________________________________________________
batch_normalization_1 (Batch (None, 72)                288
_________________________________________________________________
dense_1 (Dense)              (None, 12)                876
_________________________________________________________________
dropout_1 (Dropout)          (None, 12)                0
_________________________________________________________________
dense_2 (Dense)              (None, 1)                 13
=================================================================
Total params: 1,177
Trainable params: 1,033
Non-trainable params: 144
_________________________________________________________________
None
Train on 496 samples, validate on 128 samples
Epoch 1/100
2018-07-16 07:31:26.333255: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
496/496 [==============================] - 1s 1ms/step - loss: 0.2878 - acc: 0.5403 - val_loss: 0.2126 - val_acc: 0.6719
Epoch 2/100
496/496 [==============================] - 0s 71us/step - loss: 0.1987 - acc: 0.6976 - val_loss: 0.1389 - val_acc: 0.8516
Epoch 3/100
496/496 [==============================] - 0s 83us/step - loss: 0.1510 - acc: 0.8004 - val_loss: 0.1089 - val_acc: 0.9062
Epoch 4/100
496/496 [==============================] - 0s 82us/step - loss: 0.1319 - acc: 0.8105 - val_loss: 0.0931 - val_acc: 0.9141
Epoch 5/100
496/496 [==============================] - 0s 87us/step - loss: 0.1219 - acc: 0.8327 - val_loss: 0.0835 - val_acc: 0.9141
Epoch 6/100
496/496 [==============================] - 0s 80us/step - loss: 0.1170 - acc: 0.8508 - val_loss: 0.0775 - val_acc: 0.9141
Epoch 7/100
496/496 [==============================] - 0s 89us/step - loss: 0.0940 - acc: 0.8810 - val_loss: 0.0726 - val_acc: 0.9141
Epoch 8/100
496/496 [==============================] - 0s 109us/step - loss: 0.0907 - acc: 0.8871 - val_loss: 0.0697 - val_acc: 0.9141
Epoch 9/100
496/496 [==============================] - 0s 69us/step - loss: 0.0869 - acc: 0.8972 - val_loss: 0.0673 - val_acc: 0.9219
Epoch 10/100
496/496 [==============================] - 0s 85us/step - loss: 0.0789 - acc: 0.8972 - val_loss: 0.0656 - val_acc: 0.9219
Epoch 11/100
496/496 [==============================] - 0s 81us/step - loss: 0.0793 - acc: 0.9052 - val_loss: 0.0642 - val_acc: 0.9219
Epoch 12/100
496/496 [==============================] - 0s 89us/step - loss: 0.0735 - acc: 0.9153 - val_loss: 0.0621 - val_acc: 0.9297
Epoch 13/100
496/496 [==============================] - 0s 76us/step - loss: 0.0804 - acc: 0.9012 - val_loss: 0.0604 - val_acc: 0.9375
Epoch 14/100
496/496 [==============================] - 0s 100us/step - loss: 0.0707 - acc: 0.9194 - val_loss: 0.0594 - val_acc: 0.9375
Epoch 15/100
496/496 [==============================] - 0s 73us/step - loss: 0.0785 - acc: 0.9093 - val_loss: 0.0583 - val_acc: 0.9375
Epoch 16/100
496/496 [==============================] - 0s 91us/step - loss: 0.0653 - acc: 0.9234 - val_loss: 0.0578 - val_acc: 0.9375
Epoch 17/100
496/496 [==============================] - 0s 79us/step - loss: 0.0687 - acc: 0.9194 - val_loss: 0.0567 - val_acc: 0.9375
Epoch 18/100
496/496 [==============================] - 0s 93us/step - loss: 0.0766 - acc: 0.9173 - val_loss: 0.0559 - val_acc: 0.9453
Epoch 19/100
496/496 [==============================] - 0s 75us/step - loss: 0.0687 - acc: 0.9153 - val_loss: 0.0548 - val_acc: 0.9453
Epoch 20/100
496/496 [==============================] - 0s 96us/step - loss: 0.0751 - acc: 0.9032 - val_loss: 0.0546 - val_acc: 0.9453
Epoch 21/100
496/496 [==============================] - 0s 87us/step - loss: 0.0611 - acc: 0.9315 - val_loss: 0.0537 - val_acc: 0.9453
Epoch 22/100
496/496 [==============================] - 0s 110us/step - loss: 0.0775 - acc: 0.9052 - val_loss: 0.0536 - val_acc: 0.9453
Epoch 23/100
496/496 [==============================] - 0s 97us/step - loss: 0.0603 - acc: 0.9294 - val_loss: 0.0532 - val_acc: 0.9453
Epoch 24/100
496/496 [==============================] - 0s 83us/step - loss: 0.0678 - acc: 0.9173 - val_loss: 0.0530 - val_acc: 0.9453
Epoch 25/100
496/496 [==============================] - 0s 85us/step - loss: 0.0608 - acc: 0.9395 - val_loss: 0.0527 - val_acc: 0.9453
Epoch 26/100
496/496 [==============================] - 0s 84us/step - loss: 0.0711 - acc: 0.9173 - val_loss: 0.0521 - val_acc: 0.9453
Epoch 27/100
496/496 [==============================] - 0s 87us/step - loss: 0.0648 - acc: 0.9254 - val_loss: 0.0517 - val_acc: 0.9453
Epoch 28/100
496/496 [==============================] - 0s 85us/step - loss: 0.0568 - acc: 0.9395 - val_loss: 0.0516 - val_acc: 0.9453
Epoch 29/100
496/496 [==============================] - 0s 84us/step - loss: 0.0711 - acc: 0.9133 - val_loss: 0.0519 - val_acc: 0.9453
Epoch 30/100
496/496 [==============================] - 0s 100us/step - loss: 0.0583 - acc: 0.9294 - val_loss: 0.0525 - val_acc: 0.9453
Epoch 31/100
496/496 [==============================] - 0s 102us/step - loss: 0.0705 - acc: 0.9133 - val_loss: 0.0524 - val_acc: 0.9453
Epoch 32/100
496/496 [==============================] - 0s 72us/step - loss: 0.0622 - acc: 0.9294 - val_loss: 0.0521 - val_acc: 0.9453
Epoch 33/100
496/496 [==============================] - 0s 91us/step - loss: 0.0603 - acc: 0.9294 - val_loss: 0.0518 - val_acc: 0.9453
Epoch 34/100
496/496 [==============================] - 0s 86us/step - loss: 0.0611 - acc: 0.9294 - val_loss: 0.0513 - val_acc: 0.9453
Epoch 35/100
496/496 [==============================] - 0s 84us/step - loss: 0.0693 - acc: 0.9032 - val_loss: 0.0511 - val_acc: 0.9453
Epoch 36/100
496/496 [==============================] - 0s 86us/step - loss: 0.0658 - acc: 0.9153 - val_loss: 0.0513 - val_acc: 0.9453
Epoch 37/100
496/496 [==============================] - 0s 89us/step - loss: 0.0654 - acc: 0.9194 - val_loss: 0.0513 - val_acc: 0.9453
Epoch 38/100
496/496 [==============================] - 0s 84us/step - loss: 0.0603 - acc: 0.9294 - val_loss: 0.0512 - val_acc: 0.9453
Epoch 39/100
496/496 [==============================] - 0s 89us/step - loss: 0.0623 - acc: 0.9315 - val_loss: 0.0508 - val_acc: 0.9453
Epoch 40/100
496/496 [==============================] - 0s 87us/step - loss: 0.0629 - acc: 0.9254 - val_loss: 0.0510 - val_acc: 0.9453
Epoch 41/100
496/496 [==============================] - 0s 75us/step - loss: 0.0611 - acc: 0.9335 - val_loss: 0.0510 - val_acc: 0.9453
Epoch 42/100
496/496 [==============================] - 0s 83us/step - loss: 0.0583 - acc: 0.9274 - val_loss: 0.0509 - val_acc: 0.9375
Epoch 43/100
496/496 [==============================] - 0s 69us/step - loss: 0.0644 - acc: 0.9274 - val_loss: 0.0506 - val_acc: 0.9375
Epoch 44/100
496/496 [==============================] - 0s 81us/step - loss: 0.0520 - acc: 0.9435 - val_loss: 0.0504 - val_acc: 0.9453
Epoch 45/100
496/496 [==============================] - 0s 84us/step - loss: 0.0569 - acc: 0.9315 - val_loss: 0.0503 - val_acc: 0.9531
Epoch 46/100
496/496 [==============================] - 0s 78us/step - loss: 0.0557 - acc: 0.9375 - val_loss: 0.0498 - val_acc: 0.9531
Epoch 47/100
496/496 [==============================] - 0s 86us/step - loss: 0.0536 - acc: 0.9456 - val_loss: 0.0495 - val_acc: 0.9531
Epoch 48/100
496/496 [==============================] - 0s 95us/step - loss: 0.0625 - acc: 0.9254 - val_loss: 0.0492 - val_acc: 0.9531
Epoch 49/100
496/496 [==============================] - 0s 84us/step - loss: 0.0590 - acc: 0.9294 - val_loss: 0.0492 - val_acc: 0.9531
Epoch 50/100
496/496 [==============================] - 0s 89us/step - loss: 0.0613 - acc: 0.9294 - val_loss: 0.0493 - val_acc: 0.9531
Epoch 51/100
496/496 [==============================] - 0s 81us/step - loss: 0.0562 - acc: 0.9435 - val_loss: 0.0499 - val_acc: 0.9453
Epoch 52/100
496/496 [==============================] - 0s 84us/step - loss: 0.0524 - acc: 0.9415 - val_loss: 0.0495 - val_acc: 0.9453
Epoch 53/100
496/496 [==============================] - 0s 90us/step - loss: 0.0515 - acc: 0.9415 - val_loss: 0.0496 - val_acc: 0.9453
Epoch 54/100
496/496 [==============================] - 0s 95us/step - loss: 0.0564 - acc: 0.9375 - val_loss: 0.0498 - val_acc: 0.9453
Epoch 55/100
496/496 [==============================] - 0s 105us/step - loss: 0.0551 - acc: 0.9315 - val_loss: 0.0502 - val_acc: 0.9453
Epoch 56/100
496/496 [==============================] - 0s 80us/step - loss: 0.0564 - acc: 0.9435 - val_loss: 0.0501 - val_acc: 0.9453
Epoch 57/100
496/496 [==============================] - 0s 84us/step - loss: 0.0552 - acc: 0.9415 - val_loss: 0.0498 - val_acc: 0.9453
Epoch 58/100
496/496 [==============================] - 0s 96us/step - loss: 0.0597 - acc: 0.9315 - val_loss: 0.0495 - val_acc: 0.9453
Epoch 59/100
496/496 [==============================] - 0s 86us/step - loss: 0.0579 - acc: 0.9294 - val_loss: 0.0499 - val_acc: 0.9453
Epoch 60/100
496/496 [==============================] - 0s 81us/step - loss: 0.0475 - acc: 0.9476 - val_loss: 0.0503 - val_acc: 0.9453
Epoch 61/100
496/496 [==============================] - 0s 91us/step - loss: 0.0546 - acc: 0.9375 - val_loss: 0.0501 - val_acc: 0.9453
Epoch 62/100
496/496 [==============================] - 0s 114us/step - loss: 0.0538 - acc: 0.9395 - val_loss: 0.0499 - val_acc: 0.9453
Epoch 63/100
496/496 [==============================] - 0s 69us/step - loss: 0.0559 - acc: 0.9395 - val_loss: 0.0495 - val_acc: 0.9453
Epoch 64/100
496/496 [==============================] - 0s 88us/step - loss: 0.0498 - acc: 0.9435 - val_loss: 0.0492 - val_acc: 0.9453
Epoch 65/100
496/496 [==============================] - 0s 88us/step - loss: 0.0504 - acc: 0.9496 - val_loss: 0.0492 - val_acc: 0.9453
Epoch 66/100
496/496 [==============================] - 0s 100us/step - loss: 0.0506 - acc: 0.9355 - val_loss: 0.0490 - val_acc: 0.9453
Epoch 67/100
496/496 [==============================] - 0s 104us/step - loss: 0.0527 - acc: 0.9415 - val_loss: 0.0490 - val_acc: 0.9531
Epoch 68/100
496/496 [==============================] - 0s 80us/step - loss: 0.0579 - acc: 0.9375 - val_loss: 0.0486 - val_acc: 0.9531
Epoch 69/100
496/496 [==============================] - 0s 100us/step - loss: 0.0590 - acc: 0.9335 - val_loss: 0.0484 - val_acc: 0.9531
Epoch 70/100
496/496 [==============================] - 0s 93us/step - loss: 0.0477 - acc: 0.9476 - val_loss: 0.0484 - val_acc: 0.9531
Epoch 71/100
496/496 [==============================] - 0s 80us/step - loss: 0.0556 - acc: 0.9395 - val_loss: 0.0481 - val_acc: 0.9531
Epoch 72/100
496/496 [==============================] - 0s 89us/step - loss: 0.0430 - acc: 0.9536 - val_loss: 0.0481 - val_acc: 0.9531
Epoch 73/100
496/496 [==============================] - 0s 86us/step - loss: 0.0639 - acc: 0.9254 - val_loss: 0.0480 - val_acc: 0.9531
Epoch 74/100
496/496 [==============================] - 0s 88us/step - loss: 0.0565 - acc: 0.9375 - val_loss: 0.0486 - val_acc: 0.9531
Epoch 75/100
496/496 [==============================] - 0s 87us/step - loss: 0.0452 - acc: 0.9476 - val_loss: 0.0483 - val_acc: 0.9531
Epoch 76/100
496/496 [==============================] - 0s 89us/step - loss: 0.0588 - acc: 0.9315 - val_loss: 0.0487 - val_acc: 0.9531
Epoch 77/100
496/496 [==============================] - 0s 82us/step - loss: 0.0521 - acc: 0.9395 - val_loss: 0.0489 - val_acc: 0.9531
Epoch 78/100
496/496 [==============================] - 0s 89us/step - loss: 0.0526 - acc: 0.9395 - val_loss: 0.0488 - val_acc: 0.9531
Epoch 79/100
496/496 [==============================] - 0s 88us/step - loss: 0.0469 - acc: 0.9456 - val_loss: 0.0485 - val_acc: 0.9531
Epoch 80/100
496/496 [==============================] - 0s 93us/step - loss: 0.0529 - acc: 0.9456 - val_loss: 0.0483 - val_acc: 0.9531
Epoch 81/100
496/496 [==============================] - 0s 92us/step - loss: 0.0543 - acc: 0.9335 - val_loss: 0.0481 - val_acc: 0.9531
Epoch 82/100
496/496 [==============================] - 0s 88us/step - loss: 0.0489 - acc: 0.9415 - val_loss: 0.0479 - val_acc: 0.9531
Epoch 83/100
496/496 [==============================] - 0s 88us/step - loss: 0.0628 - acc: 0.9254 - val_loss: 0.0480 - val_acc: 0.9531
Epoch 84/100
496/496 [==============================] - 0s 82us/step - loss: 0.0581 - acc: 0.9254 - val_loss: 0.0477 - val_acc: 0.9531
Epoch 85/100
496/496 [==============================] - 0s 96us/step - loss: 0.0527 - acc: 0.9415 - val_loss: 0.0472 - val_acc: 0.9531
Epoch 86/100
496/496 [==============================] - 0s 100us/step - loss: 0.0523 - acc: 0.9435 - val_loss: 0.0477 - val_acc: 0.9531
Epoch 87/100
496/496 [==============================] - 0s 93us/step - loss: 0.0523 - acc: 0.9415 - val_loss: 0.0482 - val_acc: 0.9531
Epoch 88/100
496/496 [==============================] - 0s 93us/step - loss: 0.0635 - acc: 0.9254 - val_loss: 0.0480 - val_acc: 0.9531
Epoch 89/100
496/496 [==============================] - 0s 82us/step - loss: 0.0619 - acc: 0.9214 - val_loss: 0.0485 - val_acc: 0.9531
Epoch 90/100
496/496 [==============================] - 0s 87us/step - loss: 0.0489 - acc: 0.9395 - val_loss: 0.0485 - val_acc: 0.9531
Epoch 91/100
496/496 [==============================] - 0s 73us/step - loss: 0.0573 - acc: 0.9355 - val_loss: 0.0486 - val_acc: 0.9531
Epoch 92/100
496/496 [==============================] - 0s 75us/step - loss: 0.0515 - acc: 0.9456 - val_loss: 0.0494 - val_acc: 0.9531
Epoch 93/100
496/496 [==============================] - 0s 88us/step - loss: 0.0567 - acc: 0.9335 - val_loss: 0.0487 - val_acc: 0.9531
Epoch 94/100
496/496 [==============================] - 0s 87us/step - loss: 0.0529 - acc: 0.9395 - val_loss: 0.0483 - val_acc: 0.9531
Epoch 95/100
496/496 [==============================] - 0s 85us/step - loss: 0.0657 - acc: 0.9234 - val_loss: 0.0491 - val_acc: 0.9531
Epoch 96/100
496/496 [==============================] - 0s 88us/step - loss: 0.0554 - acc: 0.9355 - val_loss: 0.0493 - val_acc: 0.9531
Epoch 97/100
496/496 [==============================] - 0s 83us/step - loss: 0.0544 - acc: 0.9355 - val_loss: 0.0489 - val_acc: 0.9531
Epoch 98/100
496/496 [==============================] - 0s 93us/step - loss: 0.0647 - acc: 0.9234 - val_loss: 0.0486 - val_acc: 0.9531
Epoch 99/100
496/496 [==============================] - 0s 92us/step - loss: 0.0523 - acc: 0.9415 - val_loss: 0.0486 - val_acc: 0.9531
Epoch 100/100
496/496 [==============================] - 0s 88us/step - loss: 0.0428 - acc: 0.9536 - val_loss: 0.0486 - val_acc: 0.9531
Data saved at /Users/brendonm/banded_low_resolution_time1531740691_epoch99.json
