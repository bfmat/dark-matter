2018_06_26_0_meaningless_predictions.json: I tried to use the banded Fourier transform to distinguish between the background runs and the calibration runs. I found it to perform poorly, and also that the AP as it is is useless. Some further cuts are almost certainly required.
2018_06_26_1_perfect_ap_simulation.json: I added a bad attempt at an AP cut. The network just ended up simulating the AP function (quite well, in fact) but since the AP was determined in the last experiment to be useless at the moment, there is nothing meaningful here.
2018_06_29_improved_bubble_number_cut.json: There seems to be light at the end of the tunnel. I replaced the image-based bubble number filter with one based on the pressure transducer. After this cut, the data, while still quite noisy, has a much clearer separation between neutrons and alphas in both the neural network and AP axes.
2018_06_29_first_proper_fiducial_cuts.json: I added the original fiducial cuts used in previous research. It is starting to look much more reasonable; there are many more neutrons than alphas, but they are distinguished into a blob on the AP axis, outliers besides. However, the neural network's outputs are almost all less than 0.5 and some even go negative.
2018_06_29_improved_fiducial_cuts_with_sigmoid.json: I added a sigmoid activation on the final layer to prevent the negative results. It now looks pretty near the graph that was presented in the paper! The alphas are vastly outnumbered by neutrons. There are still neutron outliers, and over half of them are classified as alphas. That said, almost all of the alphas are classified as alphas. Not a perfect result, but it closely resembles what is shown in the PICO-60 paper.
